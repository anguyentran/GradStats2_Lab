{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Assignment 5 \n",
    "\n",
    "\n",
    "Anh Nguyen Tran\n",
    "\n",
    "Factors Predicting Democratic Party Identification\n",
    "\n",
    "04/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.jp-Notebook .datagrid-container {min-height: 448px; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "// Setting up Data\n",
    "\n",
    "set maxvar 20000\n",
    "use /Users/anhnguyentran/Desktop/GradStats2_Lab/GSS_1972_2021.dta, clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Keeping only variables I need\n",
    "keep partyid sex race rincome polviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       political party affiliation |      Freq.     Percent        Cum.\n",
      "-----------------------------------+-----------------------------------\n",
      "                   strong democrat |     11,200       16.38       16.38\n",
      "          not very strong democrat |     13,835       20.23       36.60\n",
      "    independent, close to democrat |      8,263       12.08       48.68\n",
      "independent (neither, no response) |     10,705       15.65       64.34\n",
      "  independent, close to republican |      6,048        8.84       73.18\n",
      "        not very strong republican |     10,317       15.08       88.26\n",
      "                 strong republican |      6,842       10.00       98.27\n",
      "                       other party |      1,186        1.73      100.00\n",
      "-----------------------------------+-----------------------------------\n",
      "                             Total |     68,396      100.00\n",
      "\n",
      "  political |\n",
      "      party |\n",
      "affiliation |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          0 |     11,200       16.38       16.38\n",
      "          1 |     13,835       20.23       36.60\n",
      "          2 |      8,263       12.08       48.68\n",
      "          3 |     10,705       15.65       64.34\n",
      "          4 |      6,048        8.84       73.18\n",
      "          5 |     10,317       15.08       88.26\n",
      "          6 |      6,842       10.00       98.27\n",
      "          7 |      1,186        1.73      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |     68,396      100.00\n",
      "(450 missing values generated)\n",
      "(11,200 real changes made)\n",
      "(55,011 real changes made)\n"
     ]
    }
   ],
   "source": [
    "// Turning dependent variable into dummy/dichotomous variable\n",
    "tab partyid\n",
    "tab partyid, nol\n",
    "\n",
    "gen democrat=partyid\n",
    "replace democrat=1 if partyid==0 | partyid==1\n",
    "replace democrat=0 if partyid!=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "// Labeling dependent variable\n",
    "\n",
    "label variable democrat \"Identifies as Democrat\"\n",
    "label define democrat 0 \"Not Democrat\" 1 \"Democrat\"\n",
    "label values democrat democrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              respondents sex |      Freq.     Percent        Cum.\n",
      "------------------------------+-----------------------------------\n",
      "                         male |     30,350       44.14       44.14\n",
      "                       female |     38,404       55.86      100.00\n",
      "------------------------------+-----------------------------------\n",
      "                        Total |     68,754      100.00\n",
      "\n",
      "           race of respondent |      Freq.     Percent        Cum.\n",
      "------------------------------+-----------------------------------\n",
      "                        white |     55,143       80.16       80.16\n",
      "                        black |      9,650       14.03       94.19\n",
      "                        other |      3,999        5.81      100.00\n",
      "------------------------------+-----------------------------------\n",
      "                        Total |     68,792      100.00\n",
      "\n",
      "           respondents income |      Freq.     Percent        Cum.\n",
      "------------------------------+-----------------------------------\n",
      "                 under $1,000 |      1,342        3.33        3.33\n",
      "             $1,000 to $2,999 |      1,917        4.75        8.08\n",
      "             $3,000 to $3,999 |      1,271        3.15       11.23\n",
      "             $4,000 to $4,999 |      1,079        2.67       13.90\n",
      "             $5,000 to $5,999 |      1,123        2.78       16.69\n",
      "             $6,000 to $6,999 |      1,020        2.53       19.22\n",
      "             $7,000 to $7,999 |      1,011        2.51       21.72\n",
      "             $8,000 to $9,999 |      1,788        4.43       26.15\n",
      "           $10,000 to $14,999 |      5,025       12.46       38.61\n",
      "           $15,000 to $19,999 |      3,957        9.81       48.42\n",
      "           $20,000 to $24,999 |      3,985        9.88       58.30\n",
      "              $25,000 or more |     16,825       41.70      100.00\n",
      "------------------------------+-----------------------------------\n",
      "                        Total |     40,343      100.00\n",
      "\n",
      "  think of self as liberal or |\n",
      "                 conservative |      Freq.     Percent        Cum.\n",
      "------------------------------+-----------------------------------\n",
      "            extremely liberal |      1,889        3.19        3.19\n",
      "                      liberal |      7,137       12.04       15.22\n",
      "             slightly liberal |      7,500       12.65       27.87\n",
      " moderate, middle of the road |     22,747       38.36       66.24\n",
      "        slightly conservative |      9,166       15.46       81.70\n",
      "                 conservative |      8,847       14.92       96.62\n",
      "       extremely conservative |      2,006        3.38      100.00\n",
      "------------------------------+-----------------------------------\n",
      "                        Total |     59,292      100.00\n"
     ]
    }
   ],
   "source": [
    "// Taking a quick look at my independent variables\n",
    "tab sex\n",
    "tab race\n",
    "tab rincome\n",
    "tab polviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   think of |\n",
      "    self as |\n",
      " liberal or |\n",
      "conservativ |\n",
      "          e |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          1 |      1,889        3.19        3.19\n",
      "          2 |      7,137       12.04       15.22\n",
      "          3 |      7,500       12.65       27.87\n",
      "          4 |     22,747       38.36       66.24\n",
      "          5 |      9,166       15.46       81.70\n",
      "          6 |      8,847       14.92       96.62\n",
      "          7 |      2,006        3.38      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |     59,292      100.00\n",
      "(9,554 missing values generated)\n",
      "(14,637 real changes made)\n",
      "(52,320 real changes made)\n",
      "\n",
      "    liberal |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          0 |     52,320       76.00       76.00\n",
      "          1 |     16,526       24.00      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |     68,846      100.00\n"
     ]
    }
   ],
   "source": [
    "// Cleaning up political ideology variable\n",
    "\n",
    "tab polviews, nol\n",
    "gen liberal=polviews\n",
    "\n",
    "replace liberal=1 if polviews==1 | polviews==2 | polviews==3\n",
    "replace liberal=0 if liberal!=1\n",
    "\n",
    "tab liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "// Labeling political ideology variable\n",
    "\n",
    "label variable liberal \"Identifies as Liberal\"\n",
    "label define liberal 0 \"Not Liberal\" 1 \"Liberal\"\n",
    "label values liberal liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    race of |\n",
      " respondent |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          1 |     55,143       80.16       80.16\n",
      "          2 |      9,650       14.03       94.19\n",
      "          3 |      3,999        5.81      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |     68,792      100.00\n",
      "(68,846 missing values generated)\n",
      "(13,649 real changes made)\n",
      "(55,143 real changes made)\n",
      "\n",
      "        poc |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          0 |     55,143       80.16       80.16\n",
      "          1 |     13,649       19.84      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |     68,792      100.00\n"
     ]
    }
   ],
   "source": [
    "// Creating a dummy for people of color\n",
    "tab race, nol\n",
    "\n",
    "gen poc=.\n",
    "\n",
    "replace poc=1 if race==2 | race==3\n",
    "replace poc=0 if race==1\n",
    "\n",
    "tab poc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "// Labeling race variable\n",
    "\n",
    "label variable poc \"Identifies as Person of Color (PoC)\"\n",
    "label define poc 0 \"Not PoC\" 1 \"PoC\"\n",
    "label values poc poc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "respondents |\n",
      "        sex |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          1 |     30,350       44.14       44.14\n",
      "          2 |     38,404       55.86      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |     68,754      100.00\n",
      "(30,442 missing values generated)\n",
      "(30,350 real changes made)\n",
      "\n",
      "     female |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          0 |     30,350       44.14       44.14\n",
      "          1 |     38,404       55.86      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |     68,754      100.00\n"
     ]
    }
   ],
   "source": [
    "// Creating a dummy for women\n",
    "tab sex, nol\n",
    "\n",
    "gen female=1 if sex==2\n",
    "replace female=0 if sex==1\n",
    "\n",
    "tab female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "// Labeling sex variable\n",
    "\n",
    "label variable female \"Identifies as Woman\"\n",
    "label define female 0 \"Not Woman\" 1 \"Woman\"\n",
    "label values female female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Develop hypotheses that approach a nominal variable in your dataset as a dependent variable (DV). [1 pt]\n",
    "\n",
    "* If your nominal variable has more than two categorical variables, such as political party affiliation categories of -- Democrat, Democratic Socialist, Green, Independent, or Republican -- develop hypotheses that treat being or not being in at least one of the categories as a dichotomous binomial dependent variable (DV).\n",
    "\n",
    "* Even if you are not interested in any categorical outcomes for your research project, still develop an hypothesis for at least one nominal variable in your data as a dependent variable. Thinking about potential influences on that variable could help you see if there are intervening relationships or omitted variable biases in your primary outcome of interest.\n",
    "\n",
    "Do the following when you write your hypothesis:\n",
    "\n",
    "    A. Write a separate hypothesis for each dependent variable (DV) you want to analyze.\n",
    "    \n",
    "    ---\n",
    "    Anh's Example: I hypothesize that being a person of color, being female, having higher income, and being more liberal predicts identification with the Democratic party.\n",
    "    ---\n",
    "    \n",
    "    B. For each dependent variable (DV) state the predicted direction of association between your dependent variable DV and independent variables (IVs) in your model. You can predict no relationship if you do not expect a relationship.\n",
    "    \n",
    "    ---\n",
    "    Anh's Example: The relationship between income and Democratic party identification is positive. People of color, women, and liberals have higher odds of identifying with the Democratic party.\n",
    "    ---\n",
    "    \n",
    "    C. Write a couple sentences about the theoretical reasons (prior knowledge / research) for each of your predictions\n",
    "    \n",
    "    ---\n",
    "    Anh's Note: Refer back to either literature or to just your intuition. Either is fine.\n",
    "    ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test your hypotheses [3 pts]\n",
    "\n",
    "    A. Create a frequency table for your dependent variable (DV).\n",
    "\n",
    "    B. Estimate an OLS model regressing your dichotomous dependent variable (DV) on your hypothesized independent variables (IVs) and store the results.\n",
    "    \n",
    "    C. Estimate an MLE logistic model regressing your dichotomous dependent variable (DV) on your hypothesized independent variables (IVs) and store the results.\n",
    "    \n",
    "    D. Use esttab to output the coefficients for your OLS and MLE logistic models with html formatting within your Jupyter Notebook.\n",
    "    \n",
    "    E. Use esttab to reoutput your coefficients as odd ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Identifies |\n",
      " as Democrat |      Freq.     Percent        Cum.\n",
      "-------------+-----------------------------------\n",
      "Not Democrat |     55,011       79.90       79.90\n",
      "    Democrat |     13,835       20.10      100.00\n",
      "-------------+-----------------------------------\n",
      "       Total |     68,846      100.00\n"
     ]
    }
   ],
   "source": [
    "*** PART A: Creating frequency table for dependent variable\n",
    "\n",
    "tab democrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "// Clearing stored estimates\n",
    "\n",
    "est clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear regression                               Number of obs     =     40,305\n",
      "                                                F(4, 40300)       =     149.73\n",
      "                                                Prob > F          =     0.0000\n",
      "                                                R-squared         =     0.0154\n",
      "                                                Root MSE          =     .39892\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "    democrat | Coefficient  std. err.      t    P>|t|     [95% conf. interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "         poc |\n",
      "        PoC  |   .0698155   .0054047    12.92   0.000     .0592222    .0804089\n",
      "             |\n",
      "      female |\n",
      "      Woman  |    .037946   .0040698     9.32   0.000     .0299692    .0459229\n",
      "             |\n",
      "     liberal |\n",
      "    Liberal  |   .0745309   .0047496    15.69   0.000     .0652216    .0838402\n",
      "     rincome |   -.001822   .0006102    -2.99   0.003    -.0030179   -.0006261\n",
      "       _cons |   .1665807   .0069174    24.08   0.000     .1530224    .1801389\n",
      "------------------------------------------------------------------------------\n",
      "(est1 stored)\n"
     ]
    }
   ],
   "source": [
    "*** PART B: Estimating an OLS model and storing results\n",
    "// Use \"ro\", short for robust, to get robust standard errors\n",
    "\n",
    "eststo: reg democrat i.poc i.female i.liberal rincome, ro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0:   log pseudolikelihood = -20318.908  \n",
      "Iteration 1:   log pseudolikelihood = -20020.121  \n",
      "Iteration 2:   log pseudolikelihood = -20016.815  \n",
      "Iteration 3:   log pseudolikelihood = -20016.814  \n",
      "\n",
      "Logistic regression                                     Number of obs = 40,305\n",
      "                                                        Wald chi2(4)  = 640.48\n",
      "                                                        Prob > chi2   = 0.0000\n",
      "Log pseudolikelihood = -20016.814                       Pseudo R2     = 0.0149\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "    democrat | Coefficient  std. err.      z    P>|z|     [95% conf. interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "         poc |\n",
      "        PoC  |   .4047179   .0295128    13.71   0.000     .3468739    .4625619\n",
      "             |\n",
      "      female |\n",
      "      Woman  |   .2396837   .0255366     9.39   0.000     .1896328    .2897345\n",
      "             |\n",
      "     liberal |\n",
      "    Liberal  |   .4407745   .0267427    16.48   0.000     .3883598    .4931891\n",
      "     rincome |  -.0113516   .0036613    -3.10   0.002    -.0185276   -.0041755\n",
      "       _cons |   -1.60974   .0425172   -37.86   0.000    -1.693072   -1.526408\n",
      "------------------------------------------------------------------------------\n",
      "(est2 stored)\n",
      "\n",
      "Conditional marginal effects                            Number of obs = 40,305\n",
      "Model VCE: Robust\n",
      "\n",
      "Expression: Pr(democrat), predict()\n",
      "dy/dx wrt:  1.poc 1.female 1.liberal rincome\n",
      "At: 0.poc     =  .801439 (mean)\n",
      "    1.poc     =  .198561 (mean)\n",
      "    0.female  = .5027416 (mean)\n",
      "    1.female  = .4972584 (mean)\n",
      "    0.liberal = .7260886 (mean)\n",
      "    1.liberal = .2739114 (mean)\n",
      "    rincome   =  9.34291 (mean)\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "             |            Delta-method\n",
      "             |      dy/dx   std. err.      z    P>|z|     [95% conf. interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "         poc |\n",
      "        PoC  |   .0691317   .0053677    12.88   0.000     .0586111    .0796522\n",
      "             |\n",
      "      female |\n",
      "      Woman  |   .0381564   .0040589     9.40   0.000      .030201    .0461118\n",
      "             |\n",
      "     liberal |\n",
      "    Liberal  |   .0743488    .004742    15.68   0.000     .0650546    .0836429\n",
      "     rincome |  -.0018062   .0005826    -3.10   0.002    -.0029482   -.0006642\n",
      "------------------------------------------------------------------------------\n",
      "Note: dy/dx for factor levels is the discrete change from the base level.\n",
      "(est3 stored)\n"
     ]
    }
   ],
   "source": [
    "*** PART C: Estimating an MLE logistic model and storing results\n",
    "// Use \"ro\" again to get robust standard errors\n",
    "\n",
    "eststo: logit democrat i.poc i.female i.liberal rincome, ro\n",
    "eststo: margins, dydx(*) post atmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unexpontiated Coefficients\n",
      "---------------------------------------------------------------\n",
      "                      (1)              (2)              (3)    \n",
      "                      OLS     MLE / logi~c     MLE margin~s    \n",
      "---------------------------------------------------------------\n",
      "main                                                           \n",
      "1.poc                0.07 ***         0.40 ***         0.07 ***\n",
      "                   (0.01)           (0.03)           (0.01)    \n",
      "1.female             0.04 ***         0.24 ***         0.04 ***\n",
      "                   (0.00)           (0.03)           (0.00)    \n",
      "1.liberal            0.07 ***         0.44 ***         0.07 ***\n",
      "                   (0.00)           (0.03)           (0.00)    \n",
      "rincome             -0.00 **         -0.01 **         -0.00 ** \n",
      "                   (0.00)           (0.00)           (0.00)    \n",
      "_cons                0.17 ***        -1.61 ***                 \n",
      "                   (0.01)           (0.04)                     \n",
      "---------------------------------------------------------------\n",
      "N                   40305            40305            40305    \n",
      "---------------------------------------------------------------\n",
      "^ p<.1, * p<.05, ** p<.01, *** p<.001\n"
     ]
    }
   ],
   "source": [
    "*** PART D: Outputting Table Results\n",
    "\n",
    "esttab ///\n",
    ", cells(b(star fmt(2)) se(fmt(2) par)) stardetach  ///\n",
    "\tlegend starlevels(^ .1 * .05 ** .01 *** .001) ///\n",
    "mlabels(\"OLS\" \"MLE / logistic\" \"MLE marginal effects\") title(\"Unexpontiated Coefficients\") ///\n",
    "collabels(none) keep(1.poc 1.female 1.liberal rincome _cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Odds Ratio\n",
      "---------------------------------------------------------------\n",
      "                      (1)              (2)              (3)    \n",
      "                      OLS     MLE / logi~c     MLE margin~s    \n",
      "---------------------------------------------------------------\n",
      "main                                                           \n",
      "1.poc                1.07 ***         1.50 ***         1.07 ***\n",
      "                   (0.01)           (0.04)           (0.01)    \n",
      "1.female             1.04 ***         1.27 ***         1.04 ***\n",
      "                   (0.00)           (0.03)           (0.00)    \n",
      "1.liberal            1.08 ***         1.55 ***         1.08 ***\n",
      "                   (0.01)           (0.04)           (0.01)    \n",
      "rincome              1.00 **          0.99 **          1.00 ** \n",
      "                   (0.00)           (0.00)           (0.00)    \n",
      "---------------------------------------------------------------\n",
      "N                   40305            40305            40305    \n",
      "---------------------------------------------------------------\n",
      "Exponentiated coefficients\n",
      "^ p<.1, * p<.05, ** p<.01, *** p<.001\n"
     ]
    }
   ],
   "source": [
    "*** PART E: Outputting Table Results with Odds Ratio\n",
    "// Do this by using \"eform\"\n",
    "\n",
    "esttab ///\n",
    ", cells(b(star fmt(2)) se(fmt(2) par)) stardetach  ///\n",
    "\tlegend starlevels(^ .1 * .05 ** .01 *** .001) ///\n",
    "mlabels(\"OLS\" \"MLE / logistic\" \"MLE marginal effects\") title(\"Odds Ratio\") ///\n",
    "collabels(none) keep(1.poc 1.female 1.liberal rincome _cons) eform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Interpret your results [1 pt]\n",
    "\n",
    "Write a couple sentences answering each of the following questions:\n",
    "\n",
    "    A. How would you interpret the relationship between your dependent variable(s) (DVs) and independent variables (IVs) based on the odds ratios for you MLE logistic model?\n",
    "\n",
    "    B. Do the overall estimates support or contradict your hypotheses? Why?\n",
    "    \n",
    "    C. Is there anything suprising in your model estimates? Why?\n",
    "    \n",
    "    D. How do the OLS coefficients and their standard errors compare to the MLE estimates? Are the coefficients and standard errors larger or smaller?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part A: Interpreting Relationship\n",
    "\n",
    "Feel free to use the following format for your assignment.\n",
    "* For these interpretations, I am looking specifically at the odds ratio table and looking at the marginal effects column with regards to the MLE model. For odds ratios that are greater than 1 (which are positive odds ratios), you can substract the value by one and interpret it as a positive percent. For odds ratios less than 1 (which are negative odds ratios), you can also substract the value by one and interpret the value as a negative percent. \n",
    "\n",
    "Interpreting for nominal or dichotomous independent variables:\n",
    "* Anh's example: The odds of identifying as Democrat is 7% more for people of color compared to white people. The odds of identifying as Democrat is 4% more for women compared to men. The odds of identifying as Democrat is 8% more for liberals compared to people who do not consider themselves to be liberal.\n",
    "\n",
    "Interpreting for interval-ratio or continuous independent variables:\n",
    "* Anh's example: For every one unit increase in respondent's income, there is a 0% increase in the odds of identifying as a Democrat. (This happens sometimes with results, where you get a statistically significant result but the odds ratio is 1.00 (or the coefficient is 0.00). A result like this indicates that the predictor/independent variable has either no effect or a very small/negligible effect on the outcome/dependent variable.)\n",
    "\n",
    "When interpreting the unexponentiated coefficients, you would say something like \"The log odds for being a person of color and identifying as a Democrat is 0.07.\"\n",
    "* As Charlie implied during lecture, unexponentiated coefficients are hard to interpret. It is not intuitive for most people to look at that and understand what log odds is. That is why we transform the unexponentiated coefficients into odds ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part B: Comparing Results to Hypothesis\n",
    "\n",
    "Refer back to the directions/general results you expected to find.\n",
    "* Anh's example: The results provide some supporting evidence for my hypothesis. I expected to find that women, people of color, and liberals have higher odds of identifying as Democrats, and my findings support my predictions. Surprisingly however, there appears to be no relationship between income and identification with the Democratic party."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part C: Surprising Findings\n",
    "\n",
    "Part C is asking about which results are surprising based on intuition or what you know about the literature.\n",
    "* Anh's example: I am surprised to see that income seemingly has no effect on party identification as a Democrat. Past research suggests that richer people tend to be Republicans rather than Democrats, but my result implies that this relationship may not be straightforward (as in income may not be the sole or even an important factor in party identification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part D: OLS VS MLE Results\n",
    "\n",
    "Focus on magnitude, direction, and standard errors of the unexponentiated coefficients between the OLS and MLE marginal effects columns. If there are differences, state what is different (no need to explain why- if there is a difference, there is simply a difference).\n",
    "* Anh's example: The magnitude, direction, and standard errors of my findings are comparable between the OLS and MLE models. There appears to be virtually no difference in the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes from Anh\n",
    "\n",
    "#### You don't have to include this following section in your assignment. This is just for your information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is maximum likelihood estimation (MLE)?\n",
    "\n",
    "Maximum likelihood estimation involves finding \"parameters that maximizes the likelihood of observing the sample data\" (Treiman 2009:302). This process is what Charlie was trying to show us in class on the Excel sheet. You do not have to understand exactly how the math behind MLE is occurring; just remember that the process for generating results behind MLE is different than it is for OLS.\n",
    "* Remember- likelihood is different than probability. With MLE, you are examining \"the likelihood of the parameters μ and σ taking certain values given that we’ve observed a bunch of data\" versus with OLS which has you examining \"the probability density of observing the data with model parameters μ and σ\" (reference this link for more information: https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1).\n",
    "\n",
    "MLE comes with its own assumptions, similar to the assumptions of linear models which focus on minimizing the error of the sum of squares (OLS = ordinary least squares).\n",
    "\n",
    "Assumptions of MLE:\n",
    "1. Independence of errors: The observations are not related to one another.\n",
    "2. Absence of multicollinearity: The independent variables are not highly correlated with one another.\n",
    "    * Use the \"vif\" command in Stata to calculate the variance inflation scores and test for multicollinearity. \n",
    "    \n",
    "3. Linearity in relationship between independent variables and log odds (aka the logit of the dependent variable): \n",
    "    * This assumption comes from the use of the following function in MLE:\n",
    "    $Logit(p) = log\\frac{p}{1-p}$\n",
    "    \n",
    "4. No extreme outliers: A large/adequate sample size is needed to accurately run MLE so that the outliers you have are not numerous or influential for the overall results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why do we calculate the marginal effects (specifically marginal odds ratios) for logistic regression?\n",
    "\n",
    "We calculate the marginal effects of our logistic regression results so that we can compare coefficients/results across different models. When we get the marginal odds ratios for logistic regression, we are accounting for how the odds ratio (calculated without marginal effects) changes depending on all the independent variables that are included in a particular model.\n",
    "\n",
    "Read more on this here: https://sociologicalscience.com/download/vol_10/april/SocSci_v10_332to347.pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Probability Model vs Logistic Regression Model Debate\n",
    "\n",
    "Treiman (P. 302): \"Although as we have seen, OLS regression procedures can easily handle categorical independent  variables, they are not appropriate for categorical dependent variables, even dichotomies. In the case of dichotomous dependent variables, the assumptions of multiple regression, including in particular that errors of prediction are normally distributed, break down badly, often yielding seriously misleading results; moreover, predicted values often lie outside the logically possible range (zero to one).\"\n",
    "* To clarify, the biggest concern with the linear probability model (aka doing OLS regression for binary dependent variables) is that the results you receive may fall outside of the 0 - 1 spectrum, making the findings uninterpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Note on probit models\n",
    "\n",
    "Probit models, also used in lieu of OLS when the dependent variable is dichotomous, provide comparable results that you will see when doing logistic regression. Probit models are not common in sociology (most sociologists use logistic regression for binary dependent variables).\n",
    "* Probit models use the cumulative distribution function rather than maximum likelihood estimation. You would also calculate marginal effects for the coefficients of probit models when interpreting findings.\n",
    "* Read more on doing probit models in Stata here: https://blog.stata.com/2016/01/07/probit-or-logit-ladies-and-gentlemen-pick-your-weapon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stata (nbstata)",
   "language": "stata",
   "name": "nbstata"
  },
  "language_info": {
   "file_extension": ".do",
   "mimetype": "text/x-stata",
   "name": "stata",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
