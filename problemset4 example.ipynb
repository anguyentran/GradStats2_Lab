{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 4\n",
    "\n",
    "\n",
    "Anh Nguyen Tran\n",
    "\n",
    "Example Homework\n",
    "\n",
    "03/14/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "*Set up your data\n",
    "\n",
    "set maxvar 32000\n",
    "use GSS_1972_2021.dta, clear\n",
    "eststo clear\n",
    "keep rincome age educ race sex partyid polviews\n",
    "\n",
    "*Once again, don't forget to do \"eststo clear\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHORT RECAP: Why do we care about heteroscedasticity?\n",
    "\n",
    "1. Biased standard errors (SE): SEs are used to calculate the confidence intervals (CI). You want your confidence intervals to be as accurate as possible of the population. Don't forget too- we use CIs to do hypothesis testing, so this will also hold implications for statistical significance.\n",
    "2. OLS assumes \"constant variance of errors\" (relook at Kyle's notes for all the assumptions of the OLS model). If there is heteroscedasticity in your model, then this assumption is violated, and the question of whether your model is valid is brought into question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Visually assess heteroscedasticity [1 pt]\n",
    "\n",
    "    A. Create a scatterplot of a dependent variable and independent variable of interest from a dataset of your choice.\n",
    "    \n",
    "    B. Include a fitted line with an area graph of the confidence interval for the prediction.\n",
    "    \n",
    "    C. Write a couple sentences describing how the distribution of the data in the graph does or does not appear to be heteroscedastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%set graph_height = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%set graph_width = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "****NOTE: Once again, for simplicity, I recommend doing just bivariate models.\n",
    "\n",
    "* PART A & B: Scatterplot between an interval-ratio dependent variable and a nominal variable\n",
    "// Charlie used an interval-ratio dependent variable and an interval-ratio independent variable\n",
    "    // that makes it easier for him to graphically see heteroscedasticity (he just looks across his data for any unevenness)\n",
    "\n",
    "tw (scatter rincome partyid) ///\n",
    "(lfitci rincome partyid), ///\n",
    "ytitle(log income, size(large)) ///\n",
    "xtitle(,size(large)) legend(off) scheme(538w) ///\n",
    "title(\"Income and Party Identification\" \" \", span size(large)) ///\n",
    "aspect(1, place(west))\n",
    "\n",
    "*REMINDER: The \"lfitci\" completes the requirement for Part B (create a fitted line with a confidence interval shadow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "codebook partyid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART C: Interpretating heteroscedasticity\n",
    "\n",
    "Remember- with nominal variables, there's no inherent order (e.g., being Catholic (number label 1) is not lesser than Protestant (number label 2)) or spacing (e.g., the number label of 1 and the number label of 2 in a nominal variable represents just the category and not any inherent value to the numbers itself). That's why it's hard to just glance at this and see if there's heteroscedasticity occurring.\n",
    "\n",
    "You can still look at the spread of the income within each category of partyid to see if there are any patterns. If the spread or variability of income appears to be different across the various categories of partyid, that might suggest a form of heteroscedasticity.\n",
    "\n",
    "From my plot, the vertical spread of the points does not seem to change systematically across the categories of political party affiliation. The scatter appears relatively constant. There appears to be no heteroscedasticity happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test for heteroscedasticity [1 pt]\n",
    "\n",
    "    A. Do a Breusch-Pagan postestimation test for heteroscedasticity in your dependent variable and independent variable relationship.\n",
    "\n",
    "    B. Reestimate the regression after logging the DV or IV if appropriate and do another Breusch-Pagan test. Does logging reduce heteroscedasticity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*PART A: Breusch-Pagan test\n",
    "// Run basic regression first before doing any postestimation command\n",
    "\n",
    "quietly reg rincome partyid\n",
    "estat hettest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breusch-Pagan test recap and interpretation\n",
    "\n",
    "WHAT CHARLIE STATED IN LECTURE: \"A large chi2 statistic and low probability for chi2 indicates that heteroskedasticity is a problem.\"\n",
    "\n",
    "Why is this? The Breusch-Pagan test has a null hypothesis that the variance of the residuals is constant. The alternative hypothesis is that the variance of the residuals is NOT constant (which is heteroscedasticity). If the p-value is less than 0.05, you can reject the null hypothesis.\n",
    "\n",
    "LOOKING AT MY EXAMPLE (focus on the p-value when you are doing this):\n",
    "1. Degrees of freedom is 1 (representing that I have only one independent variable in my model). \n",
    "2. Since the p-value of 0.0176 is less than 0.05, I am rejecting the null hypothesis of constant variance. This suggests that there is statistically significant evidence of heteroscedasticity in my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*PART B: Logging variables if needed (most of you may be skipping this step)\n",
    "// Log any dependent variables you all have that are very wide-ranging (don't log age or years of education)\n",
    "    // Log variables like college net price or state grant aid (numbers that are very wide-ranging, huge, and positive)\n",
    "\n",
    "gen rincomeln = log(rincome)\n",
    "\n",
    "quietly reg rincomeln partyid\n",
    "estat hettest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tldr...\n",
    "\n",
    "There's still heteroscedasticity going on here even after I log income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Boot strap your standard errors [1 pt.]\n",
    "\n",
    "    A. Quietly reestimate your regression coefficient with convential OLS and store the results.\n",
    "    \n",
    "    B. Quietly reestimate your regression with bootstrapped standard errors and store the results.\n",
    "    \n",
    "    C. Use esttab to output the results of the two models and tell us how the bootstrap standard erros differ from the conventional results.\n",
    "    \n",
    "    D. Explain in your own words what the bootstrap procedure is doing and why it yields similar or different standard errors to the convential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*PART A: Basic OLS\n",
    "\n",
    "eststo: quietly reg rincomeln partyid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "*PART B: OLS with Bootstrapped SEs\n",
    "// NOTE: To be clear, bootstrapping standard errors still work when you have a nominal independnet variable for OLS.\n",
    "\n",
    "eststo: quietly bootstrap _b[partyid], rep(1000) nodots : ///\n",
    "    reg rincomeln partyid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "* PART C: Creating the table\n",
    "\n",
    "esttab, ///\n",
    "mlabels(\"OLS\" \"Bootstrap\") ///\n",
    "collabels(none)  ///\n",
    "cells(b(star fmt(2)) se(fmt(2) par)) ///\n",
    "starlevels(^ .1 * .05 ** .01 *** .001) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART D: Interpretation\n",
    "\n",
    "Basically, you may see changes in the standard errors (the numbers in the parantheses) and potentially in statistical significance as well. The standard errors usually increase in the bootstrap SE model, adjusting for heteroscedasticity.\n",
    "\n",
    "For my example, there is no change, which indicates that OLS is already robust on its own. Basically, my original SEs already provide a good estimate of the variability in my data, and the bootstrap sample that was generated is very similar to the original sample.\n",
    "\n",
    "What is bootstrapping doing though? Bootstrapping is a resampling technique used to estimate the sampling distribution of an estimator by sampling (with replacement) from the original data. Basically, Stata is grabbing random points from your data to create a new sampling distribution, and they are doing this to recalculate the standard error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Estimate robust standard errors [1 pt]\n",
    "\n",
    "    A. Reestimate your model with robust standard errors and store the results.\n",
    "    \n",
    "    B. Use esttab to output the results of the robust model alongside the conventional and bootstrap models and explain how the the results compare in 1 or 2 sentences.\n",
    "    \n",
    "    C. In your own words, explain how the robust standard errors procedure differs from conventional procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*PART A: OLS with Robust SEs\n",
    "\n",
    "eststo: quietly reg rincomeln partyid, robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*PART B: Creating the table (again but this time with the new model too)\n",
    "\n",
    "esttab, ///\n",
    "mlabels(\"OLS\" \"Bootstrap\" \"Robust\") ///\n",
    "collabels(none)  ///\n",
    "cells(b(star fmt(2)) se(fmt(2) par)) ///\n",
    "starlevels(^ .1 * .05 ** .01 *** .001) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART C: Interpretation\n",
    "\n",
    "What is going on in my data? There appears to be no change in standard errors between my OG model and the robust model. I can conclude this: the OLS method may actually be a good fit for the data, and the effect of any heteroscedasticity (if it's there) might be minor enough not to significantly affect the standard errors.\n",
    "\n",
    "What is robust standard errors though? As Charlie stated in lecture, \"error estimates that apply more weight to larger deviations and less weight to smaller deviations\". \n",
    "\n",
    "In general, you should always do robust standard errors. Even if nothing changes, this strengthens the validity of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cluster robust standard errors [1 pt]\n",
    "\n",
    "    A. Explain why or why not your model should be estimated with cluster robust standard errors. If yes, what is the clustering unit and why?\n",
    "    \n",
    "    B. If yes, reestimate your model with cluster robust standard errors and use esttab to output the results of the robust model alongside your other models and explain how the the results compare in 1 or 2 sentences.\n",
    "    \n",
    "    C. Write a couple sentences explaining what is the best method of standard error estimation for your models and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART A\n",
    "\n",
    "As Charlie stated in lecture, I would not do cluster robust standard errors for party identification or political ideology. Why? There is too few \"clusters\" there. The clusters for party identification would be, for instance, Democrats, Republicans, and Independents (just 3 groups).\n",
    "\n",
    "You would want to do cluster robust SEs for people from different regions (like the 50 US states), different schools (there's usually over 50 schools again in most datasets), ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "*PART B: Cluster robust SEs (most of you will be skipping this)\n",
    "// NOTE: I am doing it just to show it, but I wouldn't do it for polviews in a normal circumstance.\n",
    "\n",
    "eststo: quietly reg rincomeln partyid,  cluster(polviews)\n",
    "\n",
    "esttab, ///\n",
    "mlabels(\"OLS\" \"Bootstrap\" \"Robust\" \"Cluster\") ///\n",
    "collabels(none) drop(_cons) ///\n",
    "cells(b(star fmt(2)) se(fmt(2) par)) ///\n",
    "starlevels(^ .1 * .05 ** .01 *** .001)  legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting for Part B if needed:\n",
    "\n",
    "Once again, there's no change in SEs for this model. This indicates that there may not be clustering in variance occurring. However, the third model is no longer statistically significant. If you have a strong technical basis for this (e.g., you are looking at students from different schools and doing cluster SEs for this), this would indicate that your results may not be significant afterall after controlling for the correlation between the error terms within each cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART C: Which model should you choose?\n",
    "\n",
    "Go based off of data and model.\n",
    "\n",
    "BOOSTRAP:\n",
    "1. This can be done on representative but smaller sample sizes (depends on complexity of your model- but with anything below 200 and greater than 30, you might want to consider this method).\n",
    "2. Use for more complex models (like ones with interaction terms, non-linear relationships, or a lot of covariates).\n",
    "\n",
    "ROBUST:\n",
    "1. This is more appropriate for larger sample sizes (again, depends on the complexity of your model- with more simple models, you can have smaller sample sizes).\n",
    "2. Use for linear models if you see evidence of heteroskedasticity.\n",
    "\n",
    "CLUSTER:\n",
    "1. This should be based primarily on your dataset. Use this if you have large clusters, and you believe there may be similarities between people in those clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stata (nbstata)",
   "language": "stata",
   "name": "nbstata"
  },
  "language_info": {
   "file_extension": ".do",
   "mimetype": "text/x-stata",
   "name": "stata",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
